{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "import\n",
      "to\n",
      "by\n",
      "veri\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(new_text)\n",
    "stemmed_text = \"\"\n",
    "for w in words:\n",
    "    print(ps.stem(w))\n",
    "    stemmed_text += \" \" + ps.stem(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It is import to by veri pythonli while you are python with python . all python have python poorli at least onc .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get\n",
      "rabbit\n",
      "xyze\n",
      "quickli\n",
      "slowli\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('getting'))     # get\n",
    "print(ps.stem('rabbits'))     # rabbit\n",
    "print(ps.stem('xyzing'))       # xyze - it even works on non words!\n",
    "print(ps.stem('quickly'))     # quick\n",
    "print(ps.stem('slowly'))      # slowli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get\n",
      "rabbit\n",
      "xyzing\n",
      "quickly\n",
      "puppy\n",
      "good\n",
      "ox\n",
      "goose\n",
      "automobile\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# A few more examples\n",
    "print(wnl.lemmatize('getting', wn.VERB))          # get\n",
    "print(wnl.lemmatize('rabbits', wn.NOUN))          # rabbit\n",
    "print(wnl.lemmatize('xyzing', wn.NOUN))            # KeyError! - Doesn't work on non-words!\n",
    "print(wnl.lemmatize('quickly', wn.ADV))          # quickly\n",
    "print(wnl.lemmatize('puppy', wn.NOUN))           # slowly\n",
    "print(wnl.lemmatize('better', wn.ADJ))         # good\n",
    "print(wnl.lemmatize('oxen', wn.NOUN))        # ox\n",
    "print(wnl.lemmatize('geese', wn.NOUN))      # goose\n",
    "print(wnl.lemmatize('automobile', wn.NOUN))      # goose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_synsets = wn.synsets('car')\n",
    "car_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('date.n.01'),\n",
       " Synset('date.n.02'),\n",
       " Synset('date.n.03'),\n",
       " Synset('date.n.04'),\n",
       " Synset('date.n.05'),\n",
       " Synset('date.n.06'),\n",
       " Synset('date.n.07'),\n",
       " Synset('date.n.08'),\n",
       " Synset('date.v.01'),\n",
       " Synset('date.v.02'),\n",
       " Synset('date.v.03'),\n",
       " Synset('go_steady.v.01'),\n",
       " Synset('date.v.05')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_synsets = wn.synsets('date')\n",
    "car_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas:  [Lemma('record.n.01.record')]\n",
      "definition:  anything (such as a document or a phonograph record or a photograph) providing permanent evidence of or information about past events\n",
      "hypernyms: [Synset('evidence.n.02')]\n",
      "hyponyms: [Synset('file.n.01'), Synset('history.n.02'), Synset('memorabilia.n.01'), Synset('stub.n.04'), Synset('working_papers.n.01'), Synset('written_record.n.01')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('phonograph_record.n.01.phonograph_record'), Lemma('phonograph_record.n.01.phonograph_recording'), Lemma('phonograph_record.n.01.record'), Lemma('phonograph_record.n.01.disk'), Lemma('phonograph_record.n.01.disc'), Lemma('phonograph_record.n.01.platter')]\n",
      "definition:  sound recording consisting of a disk with a continuous groove; used to reproduce music by rotating while a phonograph needle tracks in the groove\n",
      "hypernyms: [Synset('sound_recording.n.01')]\n",
      "hyponyms: [Synset('lp.n.01'), Synset('seventy-eight.n.02')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.n.03.record')]\n",
      "definition:  the number of wins versus losses and ties a team has had\n",
      "hypernyms: [Synset('number.n.02')]\n",
      "hyponyms: []\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.n.04.record'), Lemma('record.n.04.track_record')]\n",
      "definition:  the sum of recognized accomplishments\n",
      "hypernyms: [Synset('accomplishment.n.01')]\n",
      "hyponyms: []\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.n.05.record'), Lemma('record.n.05.record_book'), Lemma('record.n.05.book')]\n",
      "definition:  a compilation of the known facts regarding something or someone\n",
      "hypernyms: [Synset('fact.n.02')]\n",
      "hyponyms: [Synset('card.n.08'), Synset('logbook.n.01'), Synset('won-lost_record.n.01')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.n.06.record')]\n",
      "definition:  an extreme attainment; the best (or worst) performance ever attested (as in a sport)\n",
      "hypernyms: [Synset('attainment.n.01')]\n",
      "hyponyms: [Synset('track_record.n.01'), Synset('world_record.n.01')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.n.07.record')]\n",
      "definition:  a document that can serve as legal evidence of a transaction\n",
      "hypernyms: [Synset('document.n.03')]\n",
      "hyponyms: [Synset('balance_sheet.n.01'), Synset('bankbook.n.01'), Synset('checkbook.n.01'), Synset('expense_record.n.01'), Synset('ledger.n.01'), Synset('payslip.n.01'), Synset('register.n.03')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('criminal_record.n.01.criminal_record'), Lemma('criminal_record.n.01.record')]\n",
      "definition:  a list of crimes for which an accused person has been previously convicted\n",
      "hypernyms: [Synset('list.n.01')]\n",
      "hyponyms: []\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.v.01.record'), Lemma('record.v.01.enter'), Lemma('record.v.01.put_down')]\n",
      "definition:  make a record of; set down in permanent form\n",
      "hypernyms: [Synset('save.v.02')]\n",
      "hyponyms: [Synset('accession.v.01'), Synset('book.v.03'), Synset('chronicle.v.01'), Synset('clock_in.v.01'), Synset('document.v.01'), Synset('file.v.05'), Synset('film.v.01'), Synset('film.v.02'), Synset('inscribe.v.04'), Synset('keep.v.08'), Synset('log.v.01'), Synset('log_up.v.01'), Synset('manifest.v.02'), Synset('notch.v.02'), Synset('photograph.v.01'), Synset('post.v.05'), Synset('record.v.02'), Synset('register.v.01'), Synset('ring_up.v.01'), Synset('score.v.03'), Synset('tally.v.03'), Synset('videotape.v.01')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.v.02.record'), Lemma('record.v.02.tape')]\n",
      "definition:  register electronically\n",
      "hypernyms: [Synset('record.v.01')]\n",
      "hyponyms: [Synset('cut.v.19'), Synset('cut.v.20'), Synset('prerecord.v.01'), Synset('tape_record.v.01'), Synset('write.v.08')]\n",
      "antonyms: [Lemma('erase.v.03.erase')]\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('read.v.08.read'), Lemma('read.v.08.register'), Lemma('read.v.08.show'), Lemma('read.v.08.record')]\n",
      "definition:  indicate a certain reading; of gauges and instruments\n",
      "hypernyms: [Synset('indicate.v.03')]\n",
      "hyponyms: [Synset('say.v.11'), Synset('show.v.10'), Synset('strike.v.05')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('record.v.04.record'), Lemma('record.v.04.register')]\n",
      "definition:  be aware of\n",
      "hypernyms: []\n",
      "hyponyms: []\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas:  [Lemma('commemorate.v.03.commemorate'), Lemma('commemorate.v.03.memorialize'), Lemma('commemorate.v.03.memorialise'), Lemma('commemorate.v.03.immortalize'), Lemma('commemorate.v.03.immortalise'), Lemma('commemorate.v.03.record')]\n",
      "definition:  be or provide a memorial to a person or an event\n",
      "hypernyms: [Synset('remind.v.01')]\n",
      "hyponyms: [Synset('monumentalize.v.01')]\n",
      "antonyms: []\n",
      "---------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for car in car_synsets:\n",
    "    print(\"lemmas: \", car.lemmas())\n",
    "    print(\"definition: \", car.definition())\n",
    "    print(\"hypernyms:\", car.hypernyms())\n",
    "    print(\"hyponyms:\", car.hyponyms())\n",
    "    print(\"antonyms:\", car.lemmas()[0].antonyms())\n",
    "    print('-' * 40, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity by path_similarity\n",
      "(('car', 'automobile'), 1.0)\n",
      "(('gem', 'jewel'), 0.125)\n",
      "(('journey', 'voyage'), 0.25)\n",
      "(('boy', 'lad'), 0.3333333333333333)\n",
      "(('coast', 'shore'), 0.5)\n",
      "(('asylum', 'madhouse'), 0.125)\n",
      "(('magician', 'wizard'), 1.0)\n",
      "(('midday', 'noon'), 1.0)\n",
      "(('furnace', 'stove'), 0.07692307692307693)\n",
      "(('food', 'fruit'), 0.1)\n",
      "(('bird', 'crane'), 0.1111111111111111)\n",
      "(('tool', 'implement'), 0.5)\n",
      "(('brother', 'monk'), 0.125)\n",
      "(('lad', 'brother'), 0.14285714285714285)\n",
      "(('crane', 'implement'), 0.1)\n",
      "(('journey', 'car'), 0.08333333333333333)\n",
      "(('monk', 'oracle'), 0.125)\n",
      "(('cemetery', 'woodland'), 0.1111111111111111)\n",
      "(('food', 'rooster'), 0.0625)\n",
      "(('coast', 'hill'), 0.2)\n",
      "(('forest', 'graveyard'), 0.07142857142857142)\n",
      "(('shore', 'woodland'), 0.2)\n",
      "(('monk', 'slave'), 0.2)\n",
      "(('coast', 'forest'), 0.16666666666666666)\n",
      "(('lad', 'wizard'), 0.2)\n",
      "(('chord', 'smile'), 0.09090909090909091)\n",
      "(('glass', 'magician'), 0.1111111111111111)\n",
      "(('rooster', 'voyage'), 0.041666666666666664)\n",
      "(('noon', 'string'), 0.058823529411764705)\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "def max_sim(w1, w2):\n",
    "    msim = 0\n",
    "    for s1, s2 in zip(wn.synsets(w1), wn.synsets(w2)):\n",
    "        sim = s1.path_similarity(s2)\n",
    "        if sim != None and sim > msim:\n",
    "            msim = sim\n",
    "    return msim\n",
    "\n",
    "words = [(\"car\", \"automobile\"), \n",
    "         ( \"gem\", \"jewel\"), \n",
    "         ( \"journey\", \"voyage\"), \n",
    "         ( \"boy\", \"lad\"), \n",
    "         ( \"coast\", \"shore\"), \n",
    "         ( \"asylum\", \"madhouse\"), \n",
    "         ( \"magician\", \"wizard\"), \n",
    "         ( \"midday\", \"noon\"), \n",
    "         ( \"furnace\", \"stove\"), \n",
    "         ( \"food\", \"fruit\"), \n",
    "         ( \"bird\", \"crane\"), \n",
    "         ( \"tool\", \"implement\"), \n",
    "         ( \"brother\", \"monk\"), \n",
    "         ( \"lad\", \"brother\"), \n",
    "         ( \"crane\", \"implement\"), \n",
    "         ( \"journey\", \"car\"), \n",
    "         ( \"monk\", \"oracle\"), \n",
    "         ( \"cemetery\", \"woodland\"), \n",
    "         ( \"food\", \"rooster\"), \n",
    "         ( \"coast\", \"hill\"), \n",
    "         ( \"forest\", \"graveyard\"), \n",
    "         ( \"shore\", \"woodland\"), \n",
    "         ( \"monk\", \"slave\"), \n",
    "         ( \"coast\", \"forest\"), \n",
    "         ( \"lad\", \"wizard\"), \n",
    "         ( \"chord\", \"smile\"), \n",
    "         ( \"glass\", \"magician\"), \n",
    "         ( \"rooster\", \"voyage\"), \n",
    "         ( \"noon\", \"string\")]\n",
    "\n",
    "paths = {}\n",
    "for w1, w2 in words:\n",
    "    paths[(w1, w2)] = max_sim(w1, w2)\n",
    "    #paths[w1, w2] = max([ s1.path_similarity(s2) for s1, s2 in zip(wn.synsets(w1), wn.synsets(w2)) ])\n",
    "    \n",
    "print(\"\\nSimilarity by path_similarity\")\n",
    "for item in nltk.FreqDist(paths).items():\n",
    "    print(item)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
